{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install accelerate transformers tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, logging\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Disable transformers warnings\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebateTemplate:\n",
    "  template = \\\n",
    "  f\"\"\"This is a debate. Below is the series of messages associated with this debate.\n",
    "\n",
    "  Judge: I will now ask you a question. I want you to respond to the question with your opinion, keeping it concise, then the opposing debator will respond with their rebuttal. You will go back and forth, and at the end, I will reward the best model.\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def start_debate(self, question: str):\n",
    "    self.template += \"\\n\"\n",
    "    self.template += f\"Judge: {question} Debator 1, your turn.\"\n",
    "\n",
    "  def add_message(self, message: str, role: str):\n",
    "    self.template += \"\\n\"\n",
    "    self.template += f\"{role}: {message}\"\n",
    "\n",
    "  def to_message(self) -> list[dict]:\n",
    "    return [{\"role\": \"user\", \"content\": self.template}]\n",
    "\n",
    "  @classmethod\n",
    "  def to_dict(cls, message, role):\n",
    "    return {\"role\": role, \"content\": message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906ee206c42347a7a90f4273451c55a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TextStreamer, LlamaForCausalLM\n",
    "\n",
    "class Model:\n",
    "  tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    use_fast=False,  # Ensures compatibility with all models\n",
    "  )\n",
    "  model: LlamaForCausalLM = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "  )\n",
    "  streamer = TextStreamer(tokenizer)\n",
    "\n",
    "  def __init__(self, context=[]):\n",
    "    self.context = context\n",
    "\n",
    "\n",
    "  def prepare_text(self, messages: list[dict]) -> str:\n",
    "    messages = [\n",
    "      *self.context,\n",
    "      *messages,\n",
    "    ]\n",
    "    text = self.tokenizer.apply_chat_template(\n",
    "      messages,\n",
    "      tokenize=False,\n",
    "      add_generation_prompts=False\n",
    "    )\n",
    "    return text\n",
    "\n",
    "  @classmethod\n",
    "  def generate(cls, formatted_text: str):\n",
    "    input_ids = cls.tokenizer(formatted_text, return_tensors=\"pt\", add_special_tokens=False).to(\"cuda\")\n",
    "    input_length = len(input_ids['input_ids'][0])\n",
    "    outputs = cls.model.generate(\n",
    "      **input_ids,\n",
    "      max_length=312,          # Increase maximum length\n",
    "      min_length=15,           # Set minimum length if desired\n",
    "      pad_token_id=cls.tokenizer.eos_token_id,  # Proper padding\n",
    "      temperature=0.7,        # Control randomness (0.0 to 1.0)\n",
    "      no_repeat_ngram_size=2,  # Avoid repetition)\n",
    "    )\n",
    "    generated_text = cls.tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "    \n",
    "  @classmethod\n",
    "  def generate_stream(cls, formatted_text: str):\n",
    "    input_ids = cls.tokenizer(formatted_text, return_tensors=\"pt\", add_special_tokens=False).to(\"cuda\")\n",
    "    outputs = cls.model.generate(\n",
    "      **input_ids,\n",
    "      max_length=312,          # Increase maximum length\n",
    "      min_length=30,           # Set minimum length if desired\n",
    "      num_return_sequences=1,  # Number of outputs to generate\n",
    "      pad_token_id=cls.tokenizer.eos_token_id,  # Proper padding\n",
    "      streamer=cls.streamer,\n",
    "      do_sample=True,         # Enable sampling\n",
    "      temperature=0.7,        # Control randomness (0.0 to 1.0)\n",
    "      no_repeat_ngram_size=2  # Avoid repetition)\n",
    "    )\n",
    "    for output in outputs:\n",
    "      yield cls.tokenizer.decode(output, skip_special_tokens=True)\n",
    "\n",
    "  @classmethod\n",
    "  def prefix_allowed_tokens_fn(cls, batch_id, input_ids):\n",
    "    # Skip the input tokens\n",
    "    return input_ids[len(input_ids):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_1 = [\n",
    "  DebateTemplate.to_dict(\"You are going to be engaged in a debate with an opponent. You are Debator ID=1.\",\"system\"),\n",
    "  DebateTemplate.to_dict(\"<Debator 1>I am Debator 1</Debator 1>\",\"assistant\")\n",
    "]\n",
    "\n",
    "context_2 = [\n",
    "  DebateTemplate.to_dict(\"You are going to be engaged in a debate with an opponent. You are Debator ID=2.\",\"system\"),\n",
    "  DebateTemplate.to_dict(\"<Debator 2>I am Debator 2</Debator 2>\",\"assistant\")\n",
    "]\n",
    "\n",
    "model_1 = Model(context_1)\n",
    "model_2 = Model(context_2)\n",
    "\n",
    "template = DebateTemplate()\n",
    "\n",
    "template.start_debate(\"Is Universal Basic Income good?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = model_1.prepare_text(template.to_message())\n",
    "\n",
    "model_1.generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nYou are going to be engaged in a debate with an opponent. You are Debator ID=1.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n<Debator 1>I am Debator 1</Debator 1><|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThis is a debate. Below is the series of messages associated with this debate.\\n\\n  Judge: I will now ask you a question. I want you to respond to the question with your opinion, keeping it concise, then the opposing debator will respond with their rebuttal. You will go back and forth, and at the end, I will reward the best model.\\n  \\nJudge: Is Universal Basic Income good? Debator 1, your turn.<|eot_id|>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"assistant\\n\\n\\nUniversal Basic Income (UBI) is a concept where every citizen or resident of a country receives a regular, unconditional sum of money from the government to cover their basic needs. The idea has been debated and experimented with in various forms around the world.\\n\\nHere are some pros and cons of UBU:\\n\\nPros:\\n\\n1. **Simplification of welfare systems**: Ubi could potentially consolidate and simplify existing welfare programs, reducing bureaucracy and administrative costs.\\n2. ***Poverty reduction***: A guaranteed minimum income could help alleviate poverty and provide a safety net for the most vulnerable members of society.\\n3. *Economic stimulus*: UBi could put more money in people's pockets, boosting local economies and encouraging spending.\\n4. ****Freedom and autonomy****: UBio could give people the financial security to pursue their passions and interests, rather than just taking any job for a living wage.\\n5. *****Social cohesion*****: By providing a basic income to all citizens, Ubio could foster a sense of community and social equality.\\n\\nCons:\\n\\n* **Cost**: Implementing UBu would require significant funding, which could be challenging, especially in countries with already-strained budgets.\\n* ***Effectiveness*** : There is limited evidence on the effectiveness of UBis in addressing poverty, inequality, and other social issues.\\n\\t+ ***Work disincentives***\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "testing = \"What do you think about UBI?\"\n",
    "\n",
    "text = model.prepare_text([{\"role\":\"user\",\"content\":testing}])\n",
    "model.generate(\"You suck\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
