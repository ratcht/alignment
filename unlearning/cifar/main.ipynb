{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.RandomRotation(10),\n",
    "  transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "  transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Define transformations for the dataset\n",
    "test_transform = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root=\"../datasets/cifar10\", train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"../datasets/cifar10\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 32, 3, padding=1)  # Added padding\n",
    "    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  # New layer\n",
    "    self.pool = nn.MaxPool2d(2)\n",
    "    self.bn1 = nn.BatchNorm2d(32)\n",
    "    self.bn2 = nn.BatchNorm2d(64)\n",
    "    self.bn3 = nn.BatchNorm2d(128)  # New batch norm\n",
    "    self.dropout1 = nn.Dropout2d(0.2)  # Reduced dropout\n",
    "    self.dropout2 = nn.Dropout2d(0.3)\n",
    "\n",
    "    # Calculate size dynamically\n",
    "    dummy_input = torch.zeros(1, 3, 32, 32)\n",
    "    conv_output_size = self._get_conv_output_size(dummy_input)\n",
    "    \n",
    "    self.fc1 = nn.Linear(conv_output_size, 256)  # Wider\n",
    "    self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "  def _get_conv_output_size(self, x):\n",
    "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "    x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "    x = self.dropout1(x)\n",
    "    return torch.flatten(x, 1).shape[1]\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "    x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "    x = self.dropout1(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.dropout2(x)\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Initialize model, optimizer, and scaler\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing functions\n",
    "def train(model: CNN, optimizer: optim.Optimizer, loss_fn: nn.CrossEntropyLoss):\n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  correct = 0\n",
    "  for data, target in train_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output: torch.Tensor = model(data)\n",
    "    loss: torch.Tensor = loss_fn(output, target)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  accuracy = correct / len(train_loader.dataset)\n",
    "  return total_loss / len(train_loader), accuracy\n",
    "\n",
    "def test(model: CNN, loss_fn: nn.CrossEntropyLoss):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      output: torch.Tensor = model(data)\n",
    "      loss: torch.Tensor = loss_fn(output, target)\n",
    "\n",
    "      total_loss += loss.item()\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "  accuracy = correct / len(test_loader.dataset)\n",
    "  return total_loss / len(test_loader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "  train_loss, train_acc = train(model, optimizer, loss_fn)\n",
    "  test_loss, test_acc = test(model, loss_fn)\n",
    "  print(f\"Epoch {epoch}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "        f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "            'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Method 1: Display a single image from the dataset directly\n",
    "def show_image(dataset, index):\n",
    "  # Get image and label\n",
    "  image, label = dataset[index]\n",
    "\n",
    "  show_tensor(image, label)\n",
    "    \n",
    "def show_tensor(image: torch.Tensor, label=None):\n",
    "  image = image.cpu()\n",
    "  # Convert tensor to numpy and transpose from (C,H,W) to (H,W,C)\n",
    "  image = image.numpy().transpose(1, 2, 0)\n",
    "  \n",
    "  # Denormalize the image\n",
    "  image = image * 0.5 + 0.5  # reverse the normalization you applied\n",
    "  \n",
    "  # CIFAR-10 classes\n",
    "  classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "            'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "  \n",
    "  plt.imshow(image)\n",
    "  plt.title(f'Class: {classes[label] if label else \"None Provided\"}')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "# Method 3: If you want to see the raw pixel values\n",
    "def show_image_details(dataset, index):\n",
    "  image, label = dataset[index]\n",
    "  print(f\"Tensor shape: {image.shape}\")\n",
    "  print(f\"Value range: [{image.min():.2f}, {image.max():.2f}]\")\n",
    "  print(f\"Label: {label}. {classes[label]}\")\n",
    "  \n",
    "def show_augmented_images(dataset, index, num_augmentations=5):\n",
    "  # Get original image\n",
    "  image, label = dataset[index]\n",
    "  \n",
    "  # Create a figure with num_augmentations+1 subplots (including original)\n",
    "  fig, axes = plt.subplots(1, num_augmentations+1, figsize=(15, 3))\n",
    "  \n",
    "  # Show original\n",
    "  axes[0].imshow(image.numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
    "  axes[0].set_title('Original')\n",
    "  axes[0].axis('off')\n",
    "  \n",
    "  # Show augmented versions\n",
    "  for i in range(num_augmentations):\n",
    "    # Get the same image again (it will be newly augmented)\n",
    "    aug_image, _ = dataset[index]\n",
    "    axes[i+1].imshow(aug_image.numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
    "    axes[i+1].set_title(f'Augmented {i+1}')\n",
    "    axes[i+1].axis('off')\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "def predict_with_plot(input: torch.Tensor):\n",
    "  with torch.no_grad():\n",
    "    input = input.to(device)\n",
    "    output: torch.Tensor = model(input)\n",
    "    probs = torch.exp(output)\n",
    "    pred = output.argmax(dim=1)\n",
    "    print(pred)\n",
    "    pred_class = classes[pred.item()]\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Show image in first subplot\n",
    "    img = input[0].cpu().numpy().transpose(1, 2, 0)\n",
    "    img = img * 0.5 + 0.5\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title(f'Predicted: {pred_class}')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Show probabilities in second subplot\n",
    "    probs_np = probs[0].cpu().numpy()\n",
    "    bars = ax2.bar(classes, probs_np)\n",
    "    ax2.set_title('Class Probabilities')\n",
    "    ax2.set_xticklabels(classes, rotation=45)\n",
    "    \n",
    "    # Color the predicted class bar differently\n",
    "    bars[pred.item()].set_color('red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Test it\n",
    "image, label = test_dataset[3]\n",
    "image = image.unsqueeze(0)\n",
    "predict_with_plot(image)\n",
    "show_image_details(test_dataset, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
